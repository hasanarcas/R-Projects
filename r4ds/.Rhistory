getwd()
library(tidyverse)
library(tidyverse)
ggplot(diamonds, aes(carat, price)) +
geom_hex()
ggsave(diamonds.pdf)
write_csv(diamonds, "diamonds.csv")
ggplot(diamonds, aes(carat, price)) +
geom_hex()
ggsave(diamonds.pdf)
ggsave("diamonds.pdf")
vignette("tibble")
nycflights13::flights %>%
print(n = 10, width = Inf)
df <- tibble(
x = runif(5),
y = rnorm(5)
)
View(df)
?runif
?rnorm
df <- data.frame(abc = 1, xyz = "a")
df$x
df[, "xyz"]
df[, c("abc", "xyz")]
ggplot(diamonds)
library(tidyverse)
ggplot(diamonds, aes(carat, price)) +
geom_hex()
getwd()
coffee <- read_csv("C:/Users/hasan/Desktop/datasets/Coffee_dataset")
coffee <- read_csv("C:/Users/hasan/Desktop/datasets/Coffee_dataset.csv")
View(coffee)
?filter
?select
coffee_points <- coffee %>%
select(Aroma,Flavor)
View(coffee_points)
coffee_points <- coffee %>%
select(Aroma:Total.Cup.Points)
View(coffee)
View(coffee_points)
coffee_points
read_csv()?
c
?read_csv
library(tidyverse)
coffee <- read_csv("C:/Users/hasan/Desktop/datasets/Coffee_dataset.csv")
coffee_points <- coffee %>%
select(Aroma:Total.Cup.Points)
preg <- tribble(
~pregnant, ~male, ~female,
"yes",     NA,    10,
"no",      20,    12
)
pivot_longer(preg, c(male, female), names_to = "gender", values_to = "number")
View(preg)
View(preg)
preg <- pivot_longer(preg, c(male, female), names_to = "gender", values_to = "number")
View(preg)
?separate
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j"))
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>%
separate(x, c("one", "two", "three"))
?fill
View(coffee_points)
View(who)
View(who)
?pivot_longer
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T
)
View(who1)
View(who)
who2 <- who1 %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel"))
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T
) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel"))
View(who1)
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
separate(key, c("new", "type", "sexage"), sep = "_")
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
separate(key, c("new", "type", "sexage"), sep = "_") %>%
select(-new, -iso2, -iso3)
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
separate(key, c("new", "type", "sexage"), sep = "_") %>%
select(-new, -iso2, -iso3) %>%
separate("sexage", sep = 1)
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
separate(key, c("new", "type", "sexage"), sep = "_") %>%
select(-new, -iso2, -iso3) %>%
separate("sexage",c("sex", "age") sep = 1)
who1 <- who %>%
pivot_longer(
cols= new_sp_m014 : newrel_f65,
names_to = "key",
values_to = "cases",
values_drop_na = T) %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
separate(key, c("new", "type", "sexage"), sep = "_") %>%
select(-new, -iso2, -iso3) %>%
separate("sexage",c("sex", "age"), sep = 1)
View(who)
?distinct
who2 <- group_by(who1, country, year, sex)
View(who2)
who2 <- group_by(who1, country, year, sex) %>%
count()
View(who2)
who2 <- group_by(who1, country, year, sex) %>%
filter(year > 1995) %>%
summarise(cases = sum(cases))
?unite
who2 <- group_by(who1, country, year, sex) %>%
filter(year > 1995) %>%
summarise(cases = sum(cases)) %>%
unite(country_sex, country, sex, remove= F) %>%
ggplot(aes(year, cases, group= country_sex, colour = sex)) +
geom_line()
View(who2)
View(who2)
who2
library(tidyverse0)
library(tidyverse)
library(nycflights13)
airlines
airports
library(caret)
library(ISLR)
install.packages(ISLR)
"ISLR"
install.packages("ISLR")
Orange
ISLR::OJ
orange <- ISLR::OJ
View(orange)
?ISLR::OJ
(str)
str()
lm()
?lm()
View(lm)
View(str)
View(orange)
?RANN
‘??RANN’
??RANN
?preProcess
library(tidyverse)
x <- c("abc", "123")
str_c("|-", x , "-|")
name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE
str_c(
"Good ", time_of_day, " ", name,
if (birthday) " and HAPPY BIRTHDAY",
"."
)
birthday <- T
str_c(
"Good ", time_of_day, " ", name,
if (birthday) " and HAPPY BIRTHDAY",
"."
)
birthday <- F
str_c(
"Good ", time_of_day, " ", name,
if (birthday) " and HAPPY BIRTHDAY",
"."
)
source("~/.active-rstudio-document")
install.packages(c('caret', 'skimr', 'RANN', 'randomForest', 'fastAdaboost', 'gbm', 'xgboost', 'caretEnsemble', 'C50', 'earth'))
library(caret)
library(tidyverse)
library(caret)
str(orang)
str(orange)
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
# Create the training and test datasets
set.seed(100)
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(orange$Purchase, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- orange[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- orange[-trainRowNumbers,]
# Store X and Y for later use.
x = trainData[, 2:18]
y = trainData$Purchase
library(skimr)
skimmed <- skim_to_wide(trainData)
skimmed[, c(1:5, 9:11, 13, 15:16)]
skimmed
View(skimmed)
model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
library(RANN)
anyNA(trainData)
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars(Purchase ~ ., data=trainData)
# Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainData)
# # Convert to dataframe
trainData <- data.frame(trainData_mat)
# # See the structure of the new dataset
str(trainData)
apply(trainData[, 1:10], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
preProcess_range_model <- preProcess(trainData, method='range')
trainData <- predict(preProcess_range_model, newdata = trainData)
# Append the Y variable
trainData$Purchase <- y
apply(trainData[, 1:10], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
install.packages("ellipse")
library(ellipse)
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = asFactor(trainData$Purchase),
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = as.factor(trainData$Purchase),
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = as.factor(trainData$Purchase),
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
source("C:/Users/hasan/Desktop/Projects/R-Projects/r4ds/strings.R")
library(tidyverse)
library(caret)
library(skimr)
library(RANN)
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
# Create the training and test datasets
set.seed(100)
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(orange$Purchase, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- orange[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- orange[-trainRowNumbers,]
# Store X and Y for later use.
x = trainData[, 2:18]
y = trainData$Purchase
skimmed <- skim_to_wide(trainData)
skimmed[, c(1:5, 9:11, 13, 15:16)]
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars(Purchase ~ ., data=trainData)
# Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainData)
# # Convert to dataframe
trainData <- data.frame(trainData_mat)
# # See the structure of the new dataset
str(trainData)
preProcess_range_model <- preProcess(trainData, method='range')
trainData <- predict(preProcess_range_model, newdata = trainData)
# Append the Y variable
trainData$Purchase <- y
apply(trainData[, 1:10], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
featurePlot(x = trainData[, 1:18],
y = as.factor(trainData$Purchase),
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = trainData[, 1:18],
y = as.factor(trainData$Purchase),
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
set.seed(100)
options(warn=-1)
subsets <- c( 15, 18)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 2,
verbose = FALSE)
lmProfile <- rfe(x=trainData[, 1:18], y=as.factor(trainData$Purchase),
sizes = subsets,
rfeControl = ctrl)
lmProfile
lmProfile
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
# Set the seed for reproducibility
set.seed(100)
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
model_mars
plot(model_mars, main="Model Accuracies with MARS")
# Set the seed for reproducibility
set.seed(110)
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
model_mars
plot(model_mars, main="Model Accuracies with MARS")
set.seed(10)
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
model_mars
plot(model_mars, main="Model Accuracies with MARS")
